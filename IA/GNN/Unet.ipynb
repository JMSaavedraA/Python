{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Activation, Conv2D\n",
    "from keras.layers import MaxPooling2D, Dropout, UpSampling2D\n",
    "from keras.layers import BatchNormalization, Reshape\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resumen(model=None):\n",
    "    '''\n",
    "    Descipci贸n del modelo en foam compacta (la prefiero a `summary` de keras)\n",
    "    '''\n",
    "    header = '{:4} {:16} {:24} {:24} {:10}'.format('#', 'Layer Name','Layer Input Shape','Layer Output Shape','Parameters'\n",
    "    )\n",
    "    print('='*(len(header)))\n",
    "    print(header)\n",
    "    print('='*(len(header)))\n",
    "    count=0\n",
    "    count_trainable=0\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        count_trainable += layer.count_params() if layer.trainable else 0\n",
    "        input_shape = '{}'.format(layer.input_shape)\n",
    "        output_shape = '{}'.format(layer.output_shape)\n",
    "        str = '{:<4d} {:16} {:24} {:24} {:10}'.format(i,layer.name, input_shape, output_shape, layer.count_params())\n",
    "        print(str)\n",
    "        count += layer.count_params()\n",
    "    print('_'*(len(header)))\n",
    "    print('Total Parameters : ', count)\n",
    "    print('Total Trainable Parameters : ', count_trainable)\n",
    "    print('Total No-Trainable Parameters : ', count-count_trainable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# lectura de los datos\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "print('Dimensiones del conjunto de entrenamiento: ', train_images.shape)\n",
    "print('Dimensiones del conjunto de evaluaci贸n: ',    test_images.shape)\n",
    "\n",
    "num_data, nrows, ncols = train_images.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = np.copy(train_images).astype('float64')/255.\n",
    "Y_train = np.copy(train_images).astype('float64')/255.\n",
    "X_test  = np.copy(test_images).astype('float64')/255.\n",
    "Y_test  = np.copy(test_images).astype('float64')/255.\n",
    "\n",
    "sigma = 0.4\n",
    "X_train += np.random.normal(loc=0, scale=sigma, size=train_images.shape)\n",
    "X_test  += np.random.normal(loc=0, scale=sigma, size=test_images.shape)\n",
    "Y_train = Y_train>0.5\n",
    "Y_test  = Y_test>0.5\n",
    "\n",
    "num_test_images, num_rows, num_cols = X_test.shape\n",
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imgs=10\n",
    "plt.figure(figsize=(14,4))\n",
    "for i in range(imgs):\n",
    "    plt.subplot(3,imgs,i+1)\n",
    "    idx = list(train_labels).index(i)\n",
    "    plt.imshow(train_images[idx], 'gray')\n",
    "    plt.title(train_labels[idx])\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(3,imgs,i+1+imgs)\n",
    "    idx = list(train_labels).index(i)\n",
    "    plt.imshow(X_train[idx], 'gray')\n",
    "    #plt.title(train_labels[idx])\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3,imgs,i+1+2*imgs)\n",
    "    idx = list(train_labels).index(i)\n",
    "    plt.imshow(Y_train[idx], 'gray')\n",
    "    #plt.title(train_labels[idx])\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = np.expand_dims(X_train, axis=3)\n",
    "Y_train = np.expand_dims(Y_train, axis=3)\n",
    "X_test  = np.expand_dims(X_test,  axis=3)\n",
    "Y_test  = np.expand_dims(Y_test,  axis=3)\n",
    "\n",
    "print('Dimensiones de entradas (X) para entrenamiento  (imagenes x rows x cols) =', X_train.shape)\n",
    "print('Dimensiones de saida (Y) para entrenamiento     (imagenes x rows x cols) =', Y_train.shape)\n",
    "print('Dimensiones de entradas (X) para evaluaci贸n     (imagenes x rows x cols) =', X_test.shape)\n",
    "print('Dimensiones de saida (Y) para evaluaci贸n        (imagenes x rows x cols) =', Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras.layers import Conv2D, Dropout, MaxPooling2D, UpSampling2D, Concatenate\n",
    "from keras import optimizers\n",
    "from keras.backend import tf as tf\n",
    "from keras.layers import Lambda, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, num_rows, num_cols, num_channels = X_train.shape\n",
    "img_dim          = (num_rows, num_cols, num_channels,)\n",
    "filters_per_block = np.array([num_channels, 32, 64, 128])\n",
    "num_blocks        = len(filters_per_block)   \n",
    "kernel_size       = (3,3)\n",
    "drop              = 0.25*np.ones(num_blocks)\n",
    "drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm= 'encoder'\n",
    "Xdicc={}\n",
    "\n",
    "Xin  = Input(shape=img_dim, name=\"x_true\")\n",
    "\n",
    "X = Lambda(lambda image: tf.image.resize_images(image, (32, 32)))(Xin)\n",
    "# resize image layer\n",
    "Xdicc[0] = X\n",
    "numFilters=filters_per_block[0]\n",
    "print(0, numFilters, X.shape)\n",
    "\n",
    "for i in range(1,num_blocks):\n",
    "    numFilters=filters_per_block[i]\n",
    "    X = Conv2D(numFilters, kernel_size=kernel_size, padding='same', activation='relu', name='encoder-conv1'+str(i))(X) \n",
    "    X = Conv2D(numFilters, kernel_size=kernel_size, padding='same', activation='relu', name='encoder-conv2'+str(i))(X)\n",
    "    X = Dropout(rate=drop[i], name='encoder-drop'+str(i))(X)\n",
    "    X = MaxPooling2D(pool_size=(2,2), padding='valid', name='encoder-maxpool'+str(i))(X)\n",
    "    Xdicc[i] = X\n",
    "    print(i, numFilters, Xdicc[i].shape) \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=X\n",
    "for i in range(num_blocks-1,0,-1):\n",
    "    if i>1:\n",
    "        numFilters = filters_per_block[i-1] \n",
    "    else:\n",
    "        numFilters = 32\n",
    "    #print(i, numFilters, Y.shape, Xdicc[i-1].shape)\n",
    "    Y = UpSampling2D(size=2, name='decoder-up'+str(i))(Y)  \n",
    "    print(i, numFilters, Y.shape, Xdicc[i-1].shape)\n",
    "    Y = Concatenate(name='decoder-concat'+str(i))([Y, Xdicc[i-1]])\n",
    "    Y = Conv2D(numFilters, kernel_size=(3,3), padding='same', activation='relu', name='decoder-conv2'+str(i))(Y)\n",
    "    Y = Conv2D(numFilters, kernel_size=(3,3), padding='same', activation='relu', name='decoder-conv3'+str(i))(Y)\n",
    "    Y = Dropout(rate=drop[i], name='decoder-drop'+str(i))(Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
